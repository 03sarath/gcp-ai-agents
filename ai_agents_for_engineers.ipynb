{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/03sarath/gcp-ai-agents/blob/main/ai_agents_for_engineers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ur8xi4C7S06n"
      },
      "outputs": [],
      "source": [
        "# Copyright 2025 Psitron Technologies Pvt Ltd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAPoU8Sm5E6e"
      },
      "source": [
        "# AI Agents for Engineers (Evolution of AI Agents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvgnzT1CKxrO"
      },
      "source": [
        "## Overview\n",
        "\n",
        "This notebook demonstrates 3 different approaches to generating essays using the [Gemini Developer API](https://ai.google.dev/gemini-api/docs) or [Gemini API in Vertex AI](https://cloud.google.com/vertex-ai/generative-ai/docs/overview). Each method illustrates a distinct paradigm for running AI Agents in differing levels of complexity.\n",
        "\n",
        "1. Step-by-Step Approach With LangChain\n",
        "2. Iterative, AI-Agent Approach with LangGraph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61RBz8LLbxCR"
      },
      "source": [
        "## Get started"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "No17Cw5hgx12"
      },
      "source": [
        "### Install Gemini SDK and other required packages\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFy3H3aPgx12"
      },
      "outputs": [],
      "source": [
        "%pip install --upgrade --quiet \\\n",
        "    google-genai \\\n",
        "    langgraph \\\n",
        "    langchain \\\n",
        "    langchain-google-genai \\\n",
        "    langchain-google-vertexai \\\n",
        "    langchain-community \\\n",
        "    tavily-python \\\n",
        "    pydantic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5Xep4W9lq-Z"
      },
      "source": [
        "### Restart runtime\n",
        "\n",
        "To use the newly installed packages in this Jupyter runtime, you must restart the runtime. You can do this by running the cell below, which restarts the current kernel.\n",
        "\n",
        "The restart might take a minute or longer. After it's restarted, continue to the next step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XRvKdaPDTznN"
      },
      "outputs": [],
      "source": [
        "import IPython\n",
        "\n",
        "app = IPython.Application.instance()\n",
        "app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbmM4z7FOBpM"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "<b>⚠️ The kernel is going to restart. Wait until it's finished before continuing to the next step. ⚠️</b>\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1824bd79df4"
      },
      "source": [
        "### Configure Tavily\n",
        "\n",
        "Get an API key for [Tavily](https://tavily.com/), a web search API for Generative AI models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5df2f86c691f"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"TAVILY_API_KEY\"] = \"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\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e00844b64cf7"
      },
      "outputs": [],
      "source": [
        "# If your API Keys are in Colab Secrets\n",
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import userdata\n",
        "\n",
        "    os.environ[\"TAVILY_API_KEY\"] = userdata.get(\"TAVILY_API_KEY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0781fd4c9001"
      },
      "source": [
        "### Configure Gemini Developer API\n",
        "\n",
        "Get API keys from [Google AI Studio](https://ai.google.dev/gemini-api/docs/api-key) and [Tavily](https://tavily.com/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f2d2ecd0e96d"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyCrnIUPXVdI4FaM1P5ga1KOmCARuhb9HW8\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nvuDx1V6buOQ"
      },
      "outputs": [],
      "source": [
        "# If your API Keys are in Colab Secrets\n",
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import userdata\n",
        "\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = userdata.get(\"GOOGLE_API_KEY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ffb0f859dde"
      },
      "source": [
        "### Configure Vertex AI\n",
        "\n",
        "**Use a Google Cloud Project:** This requires enabling the Vertex AI API in your Google Cloud project.\n",
        "\n",
        "[Enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "885a3c84ddac"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c80118166880"
      },
      "outputs": [],
      "source": [
        "PROJECT_ID = \"clear-eye-460507-r9\"  # @param {type: \"string\", placeholder: \"[your-project-id]\", isTemplate: true}\n",
        "if not PROJECT_ID or PROJECT_ID == \"[your-project-id]\":\n",
        "    PROJECT_ID = str(os.environ.get(\"GOOGLE_CLOUD_PROJECT\"))\n",
        "\n",
        "LOCATION = os.environ.get(\"GOOGLE_CLOUD_REGION\", \"us-central1\")\n",
        "\n",
        "os.environ[\"GOOGLE_GENAI_USE_VERTEXAI\"] = \"true\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5303c05f7aa6"
      },
      "source": [
        "### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6fc324893334"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Markdown, display"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4631829d00c8"
      },
      "source": [
        "### Create Client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "898c62c59d40"
      },
      "outputs": [],
      "source": [
        "from google import genai\n",
        "\n",
        "client = genai.Client()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4b87f1f593d5"
      },
      "source": [
        "Verify which API you are using."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "84c16a5f3f33"
      },
      "outputs": [],
      "source": [
        "if not client.vertexai:\n",
        "    print(f\"Using Gemini Developer API.\")\n",
        "elif client._api_client.project:\n",
        "    print(\n",
        "        f\"Using Vertex AI with project: {client._api_client.project} in location: {client._api_client.location}\"\n",
        "    )\n",
        "elif client._api_client.api_key:\n",
        "    print(\n",
        "        f\"Using Vertex AI in express mode with API key: {client._api_client.api_key[:5]}...{client._api_client.api_key[-5:]}\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e43229f3ad4f"
      },
      "source": [
        "### Load model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cf93d5f0ce00"
      },
      "outputs": [],
      "source": [
        "MODEL_ID = \"gemini-2.0-flash-001\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16aafc60d80b"
      },
      "source": [
        "## Generating Essays Using a Step-by-Step Approach With LangChain\n",
        "\n",
        "This step demonstrates how to build an essay-writing pipeline using [LangChain](https://www.langchain.com/), the [Gemini API in Google AI Studio](https://ai.google.dev/gemini-api/docs), and [Tavily](https://tavily.com/) for search.\n",
        "\n",
        "By combining these tools, we create a seamless workflow that plans an essay outline, performs web searches for relevant information, and generates a complete essay draft based on the collected data.\n",
        "\n",
        "This solution showcases the power of chaining LLM models and external tools to tackle complex tasks with minimal human intervention, providing a robust approach to automated content generation.\n",
        "\n",
        "<img src=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/workshops/ai-agents/2-langchain-essay.png?raw=1\" width=\"550px\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85666976a359"
      },
      "source": [
        "### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "29d6e42d27ae"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Markdown, display\n",
        "from langchain import LLMChain\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain_community.tools import TavilySearchResults\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_google_vertexai import ChatVertexAI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43392590b1d8"
      },
      "source": [
        "### Initialize Gemini model & search tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6f8b0c205551"
      },
      "outputs": [],
      "source": [
        "if client.vertexai:\n",
        "    model = ChatVertexAI(project=PROJECT_ID, model=MODEL_ID, temperature=0)\n",
        "else:\n",
        "    model = ChatGoogleGenerativeAI(model=MODEL_ID, temperature=0)\n",
        "tavily_tool = TavilySearchResults(max_results=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ee8707e1867"
      },
      "source": [
        "### Define prompt templates and Runnables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a09a6a6d1f36"
      },
      "outputs": [],
      "source": [
        "# Planning: Create an outline for the marketing content\n",
        "outline_template = ChatPromptTemplate.from_template(\n",
        "    \"\"\"Create a detailed marketing content outline for {topic} that includes:\n",
        "    1. SEO-optimized title and meta description\n",
        "    2. Target audience and key personas\n",
        "    3. Main content sections with H2 and H3 headers\n",
        "    4. Key points and supporting data\n",
        "    5. Call-to-action recommendations\n",
        "    6. Content distribution strategy\n",
        "    7. Social media snippets\n",
        "    8. Internal and external linking opportunities\"\"\"\n",
        ")\n",
        "\n",
        "\n",
        "# Research: Web search\n",
        "def research_fn(topic):\n",
        "    response = tavily_tool.invoke({\"query\": topic})\n",
        "    return \"\\n\".join([f\"- {result['content']}\" for result in response])\n",
        "\n",
        "\n",
        "# Writing: Write the essay based on outline and research\n",
        "writing_template = ChatPromptTemplate.from_template(\n",
        "    \"Based on the following outline and research, write a 3-paragraph essay on '{topic}':\\n\\nOutline:\\n{outline}\\n\\nResearch:\\n{research}\\n\\nEssay:\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9a18006523f7"
      },
      "source": [
        "### Define the Runnable Chain using [LangChain Expression Language (LCEL)](https://python.langchain.com/docs/how_to/#langchain-expression-language-lcel)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cf48601613fd"
      },
      "outputs": [],
      "source": [
        "# Define individual chains\n",
        "outline_chain = LLMChain(llm=model, prompt=outline_template)\n",
        "writing_chain = LLMChain(llm=model, prompt=writing_template)\n",
        "\n",
        "# Use the pipe operator to combine chains\n",
        "chain = (\n",
        "    outline_chain\n",
        "    | (\n",
        "        lambda result: {\n",
        "            \"topic\": result[\"topic\"],\n",
        "            \"outline\": result[\"text\"],\n",
        "            \"research\": research_fn(result[\"topic\"]),\n",
        "        }\n",
        "    )\n",
        "    | writing_chain\n",
        "    | (lambda result: result[\"text\"])  # Extract the essay text from the final result\n",
        "    | StrOutputParser()\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "839fc48dd408"
      },
      "source": [
        "### Generate the essay"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a76f80ceec98"
      },
      "outputs": [],
      "source": [
        "prompt=\"Write a 3-paragraph essay about how to Implement AI in Digital Marketing Strategies\"\n",
        "essay = chain.invoke({\"topic\": prompt})\n",
        "display(Markdown(essay))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "294d3b7c43b2"
      },
      "source": [
        "## Generating Essays Using an Iterative, AI-Agent Approach with LangGraph\n",
        "\n",
        "This section demonstrates how to build a [LangGraph](https://langchain-ai.github.io/langgraph/)-powered AI agent to generate, revise, and critique essays using large language models such as Google's [Gemini API in Google AI Studio](https://ai.google.dev/gemini-api/docs) or the [Gemini API in Vertex AI](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/overview). The LangGraph code was adapted from the awesome DeepLearning.AI course on [AI Agents in LangGraph](https://www.deeplearning.ai/short-courses/ai-agents-in-langgraph/).\n",
        "\n",
        "By defining a structured state flow with nodes such as \"Planner,\" \"Research Plan,\" \"Generate,\" \"Reflect,\" and \"Research Critique,\" the system iteratively creates an essay on a given topic, incorporates feedback, and provides research-backed insights.\n",
        "\n",
        "<img src=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/workshops/ai-agents/3-langgraph-essay.png?raw=1\" width=\"900px\">\n",
        "\n",
        "The workflow enables automated essay generation with revision controls, making it ideal for structured writing tasks or educational use cases. Additionally, the notebook uses external search tools to gather and integrate real-time information into the essay content."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8e41763086f"
      },
      "source": [
        "### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "52fbe2cb7be7"
      },
      "outputs": [],
      "source": [
        "from typing import TypedDict\n",
        "\n",
        "# Common libraries\n",
        "from IPython.display import Image, Markdown, display\n",
        "\n",
        "# LangChain and LangGraph components\n",
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "\n",
        "# LangChain integrations for Gemini API in Google AI Studio and Vertex AI\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_google_vertexai import ChatVertexAI\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langgraph.graph import END, StateGraph\n",
        "\n",
        "# Typing utilities for data validation and schema definitions\n",
        "from pydantic.v1 import BaseModel\n",
        "\n",
        "# Tavily client for performing web searches\n",
        "from tavily import TavilyClient"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fc6ae1fac44f"
      },
      "source": [
        "### Initialize agent memory, agent state, and schema for search queries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6b92f7bab46d"
      },
      "outputs": [],
      "source": [
        "# Initialize agent memory\n",
        "memory = MemorySaver()\n",
        "\n",
        "\n",
        "# Define the agent's state\n",
        "class AgentState(TypedDict):\n",
        "    task: str\n",
        "    plan: str\n",
        "    draft: str\n",
        "    critique: str\n",
        "    content: list[str]\n",
        "    revision_number: int\n",
        "    max_revisions: int\n",
        "\n",
        "\n",
        "# Define a schema for search queries\n",
        "class Queries(BaseModel):\n",
        "    \"\"\"Variants of query to search for\"\"\"\n",
        "\n",
        "    queries: list[str]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9660e58afab"
      },
      "source": [
        "### Initialize Gemini model and search tool\n",
        "\n",
        "Remember to set the environment variables `GOOGLE_API_KEY` and `TAVILY_API_KEY`. And configure credentials for Vertex AI if you switch to it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ec96b00bb67f"
      },
      "outputs": [],
      "source": [
        "if client.vertexai:\n",
        "    model = ChatVertexAI(project=PROJECT_ID, model=MODEL_ID, temperature=0)\n",
        "else:\n",
        "    model = ChatGoogleGenerativeAI(model=MODEL_ID, temperature=0)\n",
        "\n",
        "# Initialize Tavily client for performing web searches\n",
        "tavily = TavilyClient()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d94dc64d3846"
      },
      "source": [
        "### Define prompt templates for each stage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2cc6f9b05d29"
      },
      "outputs": [],
      "source": [
        "PLAN_PROMPT = \"\"\"You are an expert digital marketing content strategist tasked with creating a high-level outline for a marketing piece.\n",
        "Consider SEO best practices, target audience, and key marketing objectives.\n",
        "Create an outline that includes:\n",
        "1. Target keywords and SEO focus\n",
        "2. Target audience persona\n",
        "3. Main content sections\n",
        "4. Call-to-action recommendations\n",
        "5. Content distribution strategy\"\"\"\n",
        "\n",
        "WRITER_PROMPT = \"\"\"You are a digital marketing content expert tasked with creating engaging and SEO-optimized content.\n",
        "Generate the best marketing content possible based on the user's request and the initial outline.\n",
        "If the user provides critique, respond with a revised version of your previous attempts.\n",
        "Use Markdown formatting and include:\n",
        "- SEO-optimized title\n",
        "- Meta description\n",
        "- Engaging introduction\n",
        "- Well-structured content with headers\n",
        "- Relevant internal and external links\n",
        "- Call-to-action\n",
        "- Social media snippets\n",
        "Utilize all of the information below as needed:\n",
        "---\n",
        "{content}\"\"\"\n",
        "\n",
        "REFLECTION_PROMPT = \"\"\"You are a digital marketing expert reviewing content for:\n",
        "1. SEO optimization\n",
        "2. Engagement potential\n",
        "3. Brand voice consistency\n",
        "4. Call-to-action effectiveness\n",
        "5. Social media shareability\n",
        "Provide detailed recommendations for improvement in these areas.\"\"\"\n",
        "\n",
        "RESEARCH_PLAN_PROMPT = \"\"\"You are a digital marketing researcher charged with gathering information for content creation.\n",
        "Generate a list of search queries that will help gather:\n",
        "1. Industry trends and statistics\n",
        "2. Competitor content analysis\n",
        "3. Target audience insights\n",
        "4. SEO keyword opportunities\n",
        "Only generate 3 queries max.\"\"\"\n",
        "\n",
        "RESEARCH_CRITIQUE_PROMPT = \"\"\"You are a digital marketing researcher charged with gathering additional information for content revision.\n",
        "Generate a list of search queries that will help improve:\n",
        "1. SEO performance\n",
        "2. Content engagement\n",
        "3. Market positioning\n",
        "Only generate 3 queries max.\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4f51c668222"
      },
      "source": [
        "### Define node functions for each stage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "75c8d7021369"
      },
      "outputs": [],
      "source": [
        "# Generate an outline for the essay\n",
        "\n",
        "\n",
        "def plan_node(state: AgentState):\n",
        "    messages = [SystemMessage(content=PLAN_PROMPT), HumanMessage(content=state[\"task\"])]\n",
        "    response = model.invoke(messages)\n",
        "    return {\"plan\": response.content}\n",
        "\n",
        "\n",
        "# Conducts research based on the generated plan and web search results\n",
        "def research_plan_node(state: AgentState):\n",
        "    queries = model.with_structured_output(Queries).invoke(\n",
        "        [\n",
        "            SystemMessage(content=RESEARCH_PLAN_PROMPT),\n",
        "            HumanMessage(content=state[\"task\"]),\n",
        "        ]\n",
        "    )\n",
        "    content = state[\"content\"] or []\n",
        "    for q in queries.queries:\n",
        "        response = tavily.search(query=q, max_results=2)\n",
        "        for r in response[\"results\"]:\n",
        "            content.append(r[\"content\"])\n",
        "    return {\"content\": content}\n",
        "\n",
        "\n",
        "# Generates a draft based on the content and plan\n",
        "def generation_node(state: AgentState):\n",
        "    content = \"\\n\\n\".join(state[\"content\"] or [])\n",
        "    user_message = HumanMessage(\n",
        "        content=f\"{state['task']}\\n\\nHere is my plan:\\n\\n{state['plan']}\"\n",
        "    )\n",
        "    messages = [\n",
        "        SystemMessage(content=WRITER_PROMPT.format(content=content)),\n",
        "        user_message,\n",
        "    ]\n",
        "    response = model.invoke(messages)\n",
        "    return {\n",
        "        \"draft\": response.content,\n",
        "        \"revision_number\": state.get(\"revision_number\", 1) + 1,\n",
        "    }\n",
        "\n",
        "\n",
        "# Provides feedback or critique on the draft\n",
        "def reflection_node(state: AgentState):\n",
        "    messages = [\n",
        "        SystemMessage(content=REFLECTION_PROMPT),\n",
        "        HumanMessage(content=state[\"draft\"]),\n",
        "    ]\n",
        "    response = model.invoke(messages)\n",
        "    return {\"critique\": response.content}\n",
        "\n",
        "\n",
        "# Conducts research based on the critique\n",
        "def research_critique_node(state: AgentState):\n",
        "    queries = model.with_structured_output(Queries).invoke(\n",
        "        [\n",
        "            SystemMessage(content=RESEARCH_CRITIQUE_PROMPT),\n",
        "            HumanMessage(content=state[\"critique\"]),\n",
        "        ]\n",
        "    )\n",
        "    content = state[\"content\"] or []\n",
        "    for q in queries.queries:\n",
        "        response = tavily.search(query=q, max_results=2)\n",
        "        for r in response[\"results\"]:\n",
        "            content.append(r[\"content\"])\n",
        "    return {\"content\": content}\n",
        "\n",
        "\n",
        "# Determines whether the critique and research cycle should\n",
        "# continue based on the number of revisions\n",
        "def should_continue(state):\n",
        "    if state[\"revision_number\"] > state[\"max_revisions\"]:\n",
        "        return END\n",
        "    return \"reflect\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48569416595a"
      },
      "source": [
        "### Define and compile the graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "86567ad87aa2"
      },
      "outputs": [],
      "source": [
        "# Initialize the state graph\n",
        "builder = StateGraph(AgentState)\n",
        "\n",
        "# Add nodes for each step in the workflow\n",
        "builder.add_node(\"planner\", plan_node)\n",
        "builder.add_node(\"generate\", generation_node)\n",
        "builder.add_node(\"reflect\", reflection_node)\n",
        "builder.add_node(\"research_plan\", research_plan_node)\n",
        "builder.add_node(\"research_critique\", research_critique_node)\n",
        "\n",
        "# Set the entry point of the workflow\n",
        "builder.set_entry_point(\"planner\")\n",
        "\n",
        "# Add conditional edges for task continuation or end\n",
        "builder.add_conditional_edges(\n",
        "    \"generate\", should_continue, {END: END, \"reflect\": \"reflect\"}\n",
        ")\n",
        "\n",
        "# Define task sequence edges\n",
        "builder.add_edge(\"planner\", \"research_plan\")\n",
        "builder.add_edge(\"research_plan\", \"generate\")\n",
        "\n",
        "builder.add_edge(\"reflect\", \"research_critique\")\n",
        "builder.add_edge(\"research_critique\", \"generate\")\n",
        "\n",
        "# Compile the graph with memory state management\n",
        "graph = builder.compile(checkpointer=memory)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44d87b0a2052"
      },
      "source": [
        "### Show the compiled graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9c3170874384"
      },
      "outputs": [],
      "source": [
        "Image(graph.get_graph().draw_mermaid_png())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c95bebc7e74c"
      },
      "source": [
        "### Run the agent - write on!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2a849843b454"
      },
      "outputs": [],
      "source": [
        "# Define the topic of the essay\n",
        "ESSAY_TOPIC = \"How to Implement AI in Digital Marketing Strategies\"\n",
        "\n",
        "# Define a thread configuration with a unique thread ID\n",
        "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
        "\n",
        "# Stream through the graph execution with marketing-specific state\n",
        "for s in graph.stream(\n",
        "    {\n",
        "        \"task\": ESSAY_TOPIC,\n",
        "        \"max_revisions\": 2,\n",
        "        \"revision_number\": 1,\n",
        "        \"content\": [],\n",
        "        \"target_audience\": \"Digital marketing professionals and business owners\",\n",
        "        \"keywords\": [\"AI marketing\", \"digital marketing automation\", \"marketing technology\"],\n",
        "        \"content_type\": \"blog\",\n",
        "        \"brand_voice\": \"Professional yet approachable, focusing on practical insights\"\n",
        "    },\n",
        "    thread,\n",
        "):\n",
        "    step = next(iter(s))\n",
        "    display(Markdown(f\"# {step}\"))\n",
        "    for key, content in s[step].items():\n",
        "        if key == \"revision_number\":\n",
        "            display(Markdown(f\"**Revision Number**: {content}\"))\n",
        "        elif isinstance(content, list):\n",
        "            for c in content:\n",
        "                display(Markdown(c))\n",
        "        else:\n",
        "            display(Markdown(content))\n",
        "    print(\"\\n---\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4c95d0cd7f6a"
      },
      "source": [
        "### Output the final draft of the essay"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e50e674081f2"
      },
      "outputs": [],
      "source": [
        "display(Markdown(s[\"generate\"][\"draft\"]))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "ai_agents_for_engineers.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}